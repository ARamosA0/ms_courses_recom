version: "3.4"
services:
  
  #EventBroker con kafka
  #Zookeeper
  # zookeeper:
  #   image: zookeeper:3.4.9
  #   hostname: zookeeper
  #   ulimits:
  #     nofile:
  #       soft: 65536
  #       hard: 65536
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     ZOO_MY_ID: 1
  #     ZOO_PORT: 2181
  #     ZOO_SERVERS: server.1=zookeeper:2888:3888
  #   volumes:
  #     - ./data/zookeeper/data:/data
  #     - ./data/zookeeper/datalog:/datalog
  #
  # kafka:
  #   image: confluentinc/cp-kafka:5.3.0
  #   hostname: kafka
  #   ulimits:
  #     nofile:
  #       soft: 65536
  #       hard: 65536
  #   ports:
  #     - "9091:9091"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19091,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9091
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   volumes:
  #     - ./data/kafka1/data:/var/lib/kafka/data
  #   depends_on:
  #     - zookeeper
  #
  # kafka2:
  #   image: confluentinc/cp-kafka:5.3.0
  #   hostname: kafka2
  #   ulimits:
  #     nofile:
  #       soft: 65536
  #       hard: 65536
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_BROKER_ID: 2
  #   volumes:
  #     - ./data/kafka2/data:/var/lib/kafka/data
  #   depends_on:
  #     - zookeeper 
  # kafka3:
  #   image: confluentinc/cp-kafka:5.3.0
  #   hostname: kafka3
  #   ulimits:
  #     nofile:
  #       soft: 65536
  #       hard: 65536
  #   ports:
  #     - "9093:9093"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
  #     KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   volumes:
  #     - ./data/kafka3/data:/var/lib/kafka/data
  #   depends_on:
  #     - zookeeper
  # zookeeper:
  #   image: confluentinc/cp-zookeeper
  #   hostname: zookeeper
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #   ports:
  #     - 22181:2181
  #     - 1234:1234
  #   environment:
  #     ZOOKEEPER_SERVER_ID: 1
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000
  #     ZOOKEEPER_INIT_LIMIT: 5
  #     ZOOKEEPER_SYNC_LIMIT: 2
  #     ZOOKEEPER_SERVERS: zookeeper:22888:23888
  #   networks:
  #       - kafka 
  #
  # 
  # kafka:
  #   image: confluentinc/cp-kafka  
  #   hostname: kafka
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - 29092:29092
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   networks:
  #       - kafka 

  #APIGATEWAY en Express.js
  #puerto 9090
  # apigateway:
  #   build: ./api_gateway
  #   depends_on:
  #     - kafka
  #   volumes:
  #     - ./api_gateway:/usr/local/app
  #   ports:
  #     - "9090:9090"
  #   environment:
  #     KAFKA_BROKER: kafka:9092
  #   networks:
  #     - frontend
  #     - back-process
  #     - back-tier-cursos
  #     - back-tier-usuarios
  
  #BROKER 
  #
  
  
  #KONG
  postgres:
    image: postgres:9.6-alpine
    restart: always
    hostname: kong-database
    container_name: kong-database
    environment:
      POSTGRES_USER: "kong"
      POSTGRES_DB: "kong"
      POSTGRES_PASSWORD: "kong"
    ports:
      - "5440:5432"
    networks:
      - kong-net

  kong-bootstrap:
    image: kong:2.5.0-alpine
    hostname: kong-bootstrap
    container_name: kong-bootstrap
    depends_on:
      - postgres
    environment:
      KONG_DATABASE: "postgres"
      KONG_PG_HOST: "kong-database"
      KONG_PG_DATABASE: "kong"
      KONG_PG_USER: "kong"
      KONG_PG_PASSWORD: "kong"
    command: "kong migrations bootstrap"
    restart: 'on-failure'
    networks:
      - kong-net

  kong:
    image: kong:2.5.0-alpine
    restart: always
    hostname: kong
    container_name: kong
    depends_on:
      - kong-bootstrap
    environment:
      KONG_DATABASE: "postgres"
      KONG_PG_HOST: "kong-database"
      KONG_PG_DATABASE: "kong"
      KONG_PG_USER: "kong"
      KONG_PG_PASSWORD: "kong"
      KONG_PROXY_ACCESS_LOG: '/dev/stdout'
      KONG_ADMIN_ACCESS_LOG: '/dev/stdout'
      KONG_PROXY_ERROR_LOG: '/dev/stderr'
      KONG_ADMIN_ERROR_LOG: '/dev/stderr'
      #KONG_PLUGINS: 'kafka-upstream' 
      #KONG_KAFKA_BROKER_LIST: 'kafka:29092'
      #KONG_KAFKA_TOPIC: 'getCurses'
      KONG_ADMIN_LISTEN: "0.0.0.0:8001, 0.0.0.0:8444 ssl"
    command: "kong start"
    ports:
      - "8000:8000"
      - "8443:8443"
      - "8001:8001"
      - "8444:8444"
    networks:
      - kong-net

  # puerto 3000
  frontend:
    build: ./frontend
    ports: 
      - "3000:3000"
    volumes:
      - ./frontend:/frontend
      - exclude:/frontend/node_modules/
    networks:
      - frontend
      - kong-net

  #SERVICIO para recolectar data del EventBroker
  #y guardarla en REDIS para su procesado
  #en dotnet
  collect:
    build: ./collect
    # depends_on:
      # - kafka
    volumes:
      - ./collect:/collect
    ports:
      - "6000:80"
    environment:
      KAFKA_BROKER: kafka:9092
    networks:
      - back-process
      - kong-net
      # - kafka


  #SERVICIO para el procesamiento de data
  #en python
  #puerto 5000
  procesing:
    build: 
      context: ./procesing
      target: dev
    depends_on:
      # - kafka
      - redis-collect
    healthcheck: 
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    ports:
      - "5000:83"
    environment:
      KAFKA_BROKER: kafka:9092
    volumes:
      - ./procesing:/usr/local/app
    networks:
      - back-process
      - kong-net
      - broker
      # - kafka

  #SERVICIO para crud de cursos 
  #en python
  #puerto 5001
  cursos:
    build: 
      context: ./cursos
      target: dev
    depends_on:
      # - kafka
      - db-cursos
      - redis-collect
    healthcheck: 
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    ports:
      - "5001:81"
    environment:
      KAFKA_BROKER: kafka:9092
      DATABASE_URL: postgresql://postgres-cursos:postgres-cursos@db-cursos:5432/postgres-cursos
    volumes:
      - ./cursos:/usr/local/app
    networks:
      - back-tier-cursos 
      - kong-net
      - broker
      # - kafka
    

  #SERVICIO para crud de usuarios
  #en python
  #puerto 5002
  usuarios:
    build: 
      context: ./usuarios
      target: dev   
    depends_on:
      # - kafka
      - db-usuarios
      - redis-collect
    healthcheck: 
      test: ["CMD", "curl", "-f", "http://localhost"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    ports:
      - "5002:82"
    environment:
      KAFKA_BROKER: kafka:9092
      DATABASE_URL: postgresql://postgres-usuarios:postgres-usuarios@db-usuarios:5432/postgres-usuarios
    networks:
      - back-tier-usuarios
      - kong-net 
      - broker
    volumes:
      - ./usuarios:/usr/local/app

  #BD de Usuarios en PostgreSQL
  db-usuarios:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: "postgres-usuarios"
      POSTGRES_NAME: "postgres-usuarios"
      POSTGRES_USER: "postgres-usuarios"
      POSTGRES_PASSWORD: "postgres-usuarios"
    volumes:
      - "db-data-usuarios:/var/lib/postgresql/data"
      - "./healthchecks:/healthchecks"
    ports:
      - "5432:5432"
    healthcheck:
      test: /healthchecks/postgres.sh
      interval: "5s"
    networks:
      - back-tier-usuarios

  #BD de Cursos en PostgreSQL
  db-cursos:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: "postgres-cursos"
      POSTGRES_NAME: "postgres-cursos"
      POSTGRES_USER: "postgres-cursos"
      POSTGRES_PASSWORD: "postgres-cursos"
    volumes:
      - "db-data-cursos:/var/lib/postgresql/data"
      - "./healthchecks:/healthchecks"
    ports:
      - "5433:5432"
    healthcheck:
      test: /healthchecks/postgres.sh
      interval: "5s"
    networks:
      - back-tier-cursos

  # Este REDIS se usara como broker momentaneo
  redis-collect:
    image: redis:alpine
    volumes:
      - "./healthchecks:/healthchecks"
    ports:
      - "6379:6379"
    healthcheck:
      test: /healthchecks/redis.sh
      interval: "5s"
    networks:
      - back-process
      - broker

  redis-process:
    image: redis:alpine
    volumes:
      - "./healthchecks:/healthchecks"
    ports:
      - "6380:6379"
    healthcheck:
      test: /healthchecks/redis.sh
      interval: "5s"
    networks:
      - back-process

volumes:
  exclude:
  db-data-cursos:
  db-data-usuarios:
  persist_volume:
  postgres_data:
  mongo_data:

networks:
  frontend:
  back-tier-usuarios:
  back-tier-cursos:
  back-process:
  kong-net:
  broker:
  # kafka:

